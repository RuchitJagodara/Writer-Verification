{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruchitjagodara/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import os\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import random\n",
    "import argparse, random, copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"dataset/dataset/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using vgg16 because number of variables in vgg19 are very large and it is taking too much time to train and also giving memory error\n",
    "# so although I am using vgg16 but I have written vggg19 in the code so that it can be easily changed to vgg19\n",
    "class SiameseNN(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(SiameseNN, self).__init__()\n",
    "        self.conolution = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(8, 8, kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(8, 16, kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 16, kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(3, 3),\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(4, 4),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2496, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, 8),\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.conolution(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, inp1):\n",
    "        output = self.forward_once(inp1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(path1, path2):\n",
    "    if (path1[22:].split('/')[0]==path2[22:].split('/')[0]):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    distance_positive = F.pairwise_distance(anchor, positive)\n",
    "    distance_negative = F.pairwise_distance(anchor, negative)\n",
    "    loss = torch.clamp(margin + distance_positive - distance_negative, min=0.0)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = T.CenterCrop((150, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(img_pairs, model, loss_fn, optimizer, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        random.shuffle(img_pairs)\n",
    "        for i in range(0, len(img_pairs), batch_size):\n",
    "            batch = img_pairs[i:i+batch_size]\n",
    "            anchor_images = []\n",
    "            positive_images = []\n",
    "            negative_images = []\n",
    "            for pair in batch:\n",
    "                anchor_path, positive_path = pair\n",
    "                anchor_image = Image.open(anchor_path).convert(\"L\")\n",
    "                positive_image = Image.open(positive_path).convert(\"L\")\n",
    "                anchor_image = transformer(anchor_image)\n",
    "                positive_image = transformer(positive_image)\n",
    "                negative_path = random.choice(img_pairs)[0]\n",
    "                while check(anchor_path, negative_path):\n",
    "                    negative_path = random.choice(img_pairs)[0]\n",
    "                negative_image = Image.open(negative_path).convert(\"L\")\n",
    "                negative_image = transformer(negative_image)\n",
    "                anchor_images.append(T.ToTensor()(anchor_image))\n",
    "                positive_images.append(T.ToTensor()(positive_image))\n",
    "                negative_images.append(T.ToTensor()(negative_image))\n",
    "            \n",
    "            anchor_images = torch.stack(anchor_images).to(device)\n",
    "            positive_images = torch.stack(positive_images).to(device)\n",
    "            negative_images = torch.stack(negative_images).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            anchor_embeddings = model(anchor_images)\n",
    "            positive_embeddings = model(positive_images)\n",
    "            negative_embeddings = model(negative_images)\n",
    "\n",
    "            loss = loss_fn(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((i//batch_size+1)%500==0):\n",
    "                print(f\"Epoch: {epoch+1}, iteration: {i//batch_size+1}, loss: {loss.item()}\")\n",
    "        print(\"\\n\\n------------------------------------\")\n",
    "        print(f\"Epoch: {epoch+1}, loss: {epoch_loss}\")\n",
    "        print(\"------------------------------------\\n\\n\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_pair, label, model):\n",
    "    model.eval()\n",
    "    anchor_path, test_path = img_pair\n",
    "    anchor_image = Image.open(anchor_path).convert(\"L\")\n",
    "    test_image = Image.open(test_path).convert(\"L\")\n",
    "    test_image = transformer(test_image)\n",
    "    anchor_image = transformer(anchor_image)\n",
    "\n",
    "    anchor_tensor = T.ToTensor()(anchor_image).unsqueeze(0).to(device)\n",
    "    test_tensor = T.ToTensor()(test_image).unsqueeze(0).to(device)\n",
    "\n",
    "    anchor_embedding = model(anchor_tensor)\n",
    "    test_embedding = model(test_tensor)\n",
    "\n",
    "    distance = F.pairwise_distance(anchor_embedding, test_embedding)\n",
    "    if (label == 1 and distance < 1) or (label == 0 and distance >= 1):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of parameters in the model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pairs = []\n",
    "anchors = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fld in os.listdir(data_file):\n",
    "    img_set = os.listdir(data_file+\"/\"+fld)\n",
    "    anchors[fld] = data_file+\"/\"+fld+\"/\"+img_set[0]\n",
    "    for i in range(len(img_set)):\n",
    "        for j in range(i+1, len(img_set)):\n",
    "            img = img_set[i]\n",
    "            img2 = img_set[j]\n",
    "            if (img!=img2):\n",
    "                img_pairs.append([data_file+\"/\"+fld+\"/\"+img, data_file+\"/\"+fld+\"/\"+img2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, iteration: 500, loss: 0.35691121220588684\n",
      "Epoch: 1, iteration: 1000, loss: 0.5152056813240051\n",
      "Epoch: 1, iteration: 1500, loss: 0.42794567346572876\n",
      "Epoch: 1, iteration: 2000, loss: 0.2779752016067505\n",
      "Epoch: 1, iteration: 2500, loss: 0.4004034698009491\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Epoch: 1, loss: 1307.9787173718214\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "Epoch: 2, iteration: 500, loss: 0.35440436005592346\n",
      "Epoch: 2, iteration: 1000, loss: 0.5129297971725464\n",
      "Epoch: 2, iteration: 1500, loss: 0.8183356523513794\n",
      "Epoch: 2, iteration: 2000, loss: 0.461360365152359\n",
      "Epoch: 2, iteration: 2500, loss: 0.21959036588668823\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Epoch: 2, loss: 1267.2192949354649\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "Epoch: 3, iteration: 500, loss: 0.37616997957229614\n",
      "Epoch: 3, iteration: 1000, loss: 0.3220243453979492\n",
      "Epoch: 3, iteration: 1500, loss: 0.5128110647201538\n",
      "Epoch: 3, iteration: 2000, loss: 0.7328042984008789\n",
      "Epoch: 3, iteration: 2500, loss: 0.392863929271698\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Epoch: 3, loss: 1252.3856437169015\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "Epoch: 4, iteration: 500, loss: 0.3517987132072449\n",
      "Epoch: 4, iteration: 1000, loss: 0.3986775875091553\n",
      "Epoch: 4, iteration: 1500, loss: 0.35544270277023315\n",
      "Epoch: 4, iteration: 2000, loss: 0.2972257435321808\n",
      "Epoch: 4, iteration: 2500, loss: 0.2205030620098114\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Epoch: 4, loss: 1239.0544386096299\n",
      "------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m triplet_loss\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(img_pairs, model, loss_fn, optimizer, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     positive_images\u001b[38;5;241m.\u001b[39mappend(T\u001b[38;5;241m.\u001b[39mToTensor()(positive_image))\n\u001b[1;32m     24\u001b[0m     negative_images\u001b[38;5;241m.\u001b[39mappend(T\u001b[38;5;241m.\u001b[39mToTensor()(negative_image))\n\u001b[0;32m---> 26\u001b[0m anchor_images \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_images\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m positive_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(positive_images)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     28\u001b[0m negative_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(negative_images)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = triplet_loss\n",
    "\n",
    "train(img_pairs, model, loss_fn, optimizer, batch_size, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for img_pair in random.choices(img_pairs, k=5000):\n",
    "    if (test(img_pair, 1, model)):\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3934"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "for img_pair in random.choices(img_pairs, k=5000):\n",
    "    ind += 1\n",
    "    if (ind==10000):\n",
    "        break\n",
    "    img1_path, _ = img_pair\n",
    "    img2_path = random.choice(img_pairs)[0]\n",
    "    while(check(img1_path, img2_path)):\n",
    "        img2_path = random.choice(img_pairs)[0]\n",
    "    if (test([img1_path, img2_path], 0, model)):\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3407"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
